{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da36e624-f632-46ec-9e79-f4176e73a386",
   "metadata": {},
   "source": [
    "# Using huggingface Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "989afeee-34a3-4122-be24-be2f91983145",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T05:27:58.381142Z",
     "iopub.status.busy": "2023-10-16T05:27:58.380774Z",
     "iopub.status.idle": "2023-10-16T05:28:00.770167Z",
     "shell.execute_reply": "2023-10-16T05:28:00.769427Z",
     "shell.execute_reply.started": "2023-10-16T05:27:58.381124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.34.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (4.34.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.34.0) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.34.0) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.34.0) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.34.0) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.34.0) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.34.0) (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.34.0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.34.0) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.34.0) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.34.0) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.0) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.0) (4.7.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.34.0) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.34.0) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.34.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.34.0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.34.0) (2023.5.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.34.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "578e336b-8be9-4578-98cc-c83a89ff5bb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T10:36:39.768108Z",
     "iopub.status.busy": "2023-10-16T10:36:39.767877Z",
     "iopub.status.idle": "2023-10-16T10:36:43.936122Z",
     "shell.execute_reply": "2023-10-16T10:36:43.935515Z",
     "shell.execute_reply.started": "2023-10-16T10:36:39.768091Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "model_id = \"amazon/MistralLite\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c934fec-48d2-4f18-867e-ce9283984f6f",
   "metadata": {},
   "source": [
    "## use flash attention2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56e28b8a-2ac6-4cad-b003-d1658a715ada",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T05:28:05.753680Z",
     "iopub.status.busy": "2023-10-16T05:28:05.753449Z",
     "iopub.status.idle": "2023-10-16T05:28:07.978412Z",
     "shell.execute_reply": "2023-10-16T05:28:07.977766Z",
     "shell.execute_reply.started": "2023-10-16T05:28:05.753662Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flash-attn==2.3.1.post1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.3.1.post1)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from flash-attn==2.3.1.post1) (2.0.1)\n",
      "Requirement already satisfied: einops in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from flash-attn==2.3.1.post1) (0.7.0)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from flash-attn==2.3.1.post1) (21.3)\n",
      "Requirement already satisfied: ninja in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from flash-attn==2.3.1.post1) (1.11.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging->flash-attn==2.3.1.post1) (3.0.9)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->flash-attn==2.3.1.post1) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->flash-attn==2.3.1.post1) (4.7.1)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->flash-attn==2.3.1.post1) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->flash-attn==2.3.1.post1) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->flash-attn==2.3.1.post1) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch->flash-attn==2.3.1.post1) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch->flash-attn==2.3.1.post1) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install flash-attn==2.3.1.post1 --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "679d2c9b-ee5c-4542-988a-3c0dfad894f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T05:28:07.980828Z",
     "iopub.status.busy": "2023-10-16T05:28:07.980268Z",
     "iopub.status.idle": "2023-10-16T05:28:10.100760Z",
     "shell.execute_reply": "2023-10-16T05:28:10.100007Z",
     "shell.execute_reply.started": "2023-10-16T05:28:07.980800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate==0.23.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate==0.23.0) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate==0.23.0) (21.3)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate==0.23.0) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate==0.23.0) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate==0.23.0) (2.0.1)\n",
      "Requirement already satisfied: huggingface-hub in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate==0.23.0) (0.16.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->accelerate==0.23.0) (3.0.9)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.23.0) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.23.0) (4.7.1)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.23.0) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.23.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.23.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.23.0) (2023.6.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.23.0) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.23.0) (4.65.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.23.0) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.23.0) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.23.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.23.0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.23.0) (2023.5.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.23.0) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate==0.23.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc9c8042-090b-40ff-906e-46ec26c6206a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T10:36:44.724653Z",
     "iopub.status.busy": "2023-10-16T10:36:44.724155Z",
     "iopub.status.idle": "2023-10-16T10:37:54.043893Z",
     "shell.execute_reply": "2023-10-16T10:37:54.043291Z",
     "shell.execute_reply.started": "2023-10-16T10:36:44.724630Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5eee00dab2e4b73a934a6a0dd57a465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dfdf4cfedf3427b9a8a9c1e0bfad9e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,\n",
    "                                             torch_dtype=torch.bfloat16,\n",
    "                                             use_flash_attention_2=True,\n",
    "                                             device_map=\"auto\",)\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0433b09-052b-47cb-a552-075522e4c846",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T10:37:54.045217Z",
     "iopub.status.busy": "2023-10-16T10:37:54.044883Z",
     "iopub.status.idle": "2023-10-16T10:38:11.325510Z",
     "shell.execute_reply": "2023-10-16T10:38:11.324926Z",
     "shell.execute_reply.started": "2023-10-16T10:37:54.045200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The main challenges to support a long context LLM include:\n",
      "\n",
      "1. Data availability: A long context LLM requires a large amount of data to train on, which can be difficult and expensive to collect and annotate.\n",
      "\n",
      "2. Computational resources: Training a long context LLM requires a lot of computational resources, including powerful hardware and software, which can be costly and difficult to obtain.\n",
      "\n",
      "3. Model complexity: A long context LLM is likely to be a complex model, which can be difficult to train and optimize.\n",
      "\n",
      "4. Evaluation: Evaluating the performance of a long context LLM can be challenging, as it may not be clear what metrics to use or how to interpret the results.\n",
      "\n",
      "5. Human evaluation: A long context LLM may produce outputs that are difficult for humans to understand or interpret, which can make it difficult to evaluate the model's performance.\n",
      "\n",
      "6. Ethical considerations: A long context LLM may raise ethical concerns, such as the potential for bias or the impact on privacy and security.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"<|prompter|>What are the main challenges to support a long context for LLM?</s><|assistant|>\"\n",
    "\n",
    "sequences = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=400,\n",
    "    do_sample=False,\n",
    "    return_full_text=False,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"{seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1437661-8d06-43a1-9547-ffdea1529d3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T10:41:11.163087Z",
     "iopub.status.busy": "2023-10-16T10:41:11.162680Z",
     "iopub.status.idle": "2023-10-16T10:41:37.459710Z",
     "shell.execute_reply": "2023-10-16T10:41:37.459162Z",
     "shell.execute_reply.started": "2023-10-16T10:41:11.163069Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " pgvector is an open-source extension for PostgreSQL supported by Amazon Aurora PostgreSQL-Compatible Edition.\n",
      "\n",
      "You can use pgvector to store, search, index, and query billions of embeddings that are generated from machine learning (ML) and artificial intelligence (AI) models in your database, such as those from Amazon Bedrock (limited preview) or Amazon SageMaker. A vector embedding is a numerical representation that represents the semantic meaning of content such as text, images, and video.\n",
      "\n",
      "With pgvector, you can query embeddings in your Aurora PostgreSQL database to perform efficient semantic similarity searches of these data types, represented as vectors, combined with other tabular data in Aurora. This enables the use of generative AI and other AI/ML systems for new types of applications such as personalized recommendations based on similar text descriptions or images, candidate match based on interview notes, customer service next best action recommendations based on successful transcripts or chat session dialogs, and more.\n"
     ]
    }
   ],
   "source": [
    "with open(\"../example_long_ctx.txt\", \"r\") as fin:\n",
    "    task_instruction = fin.read()\n",
    "    task_instruction = task_instruction.format(\n",
    "        my_question=\"please tell me how does pgvector help with Generative AI and give me some examples.\"\n",
    "    )\n",
    "prompt = f\"<|prompter|>{task_instruction}</s><|assistant|>\"\n",
    "sequences = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=400,\n",
    "    do_sample=False,\n",
    "    return_full_text=False,\n",
    "    num_return_sequences=1,\n",
    "    #eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"{seq['generated_text']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
